[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "statsbook",
    "section": "",
    "text": "Preface\nMy primary inspiration for wanting to revisit this work, distill the core concepts and throughlines, and then rebuild my own understanding and explanations in this book is the series of statistics courses I took during my graduate degree in data science at the University of Colorado Boulder. My background is:\nLiberal Arts -&gt; Information Technology -&gt; Databases -&gt; Project Leadership -&gt; Data Science\nThe exposure to the formal mathematics in the statistics courses and that underlie the data and machine learning work I was already doing was both challenging and engaging, so the hope is to use this book as an opportunity to go through that content more slowly and in more depth.\nNot being sure where I will attribute more concretely, this is a list of the course areas that serve as inspiration and guidance for this book:\n\nProbability with Dr. Anne Dougherty\nStatistical estimation, statistical inference, and hypothesis testing with Dr. Jem Corcoran\nRegression analysis, ANOVA, generalized linear models, and nonparametric regression with Dr. Brian Zaharatos\nRegression and classification with Dr. James Bird\nResampling, selection, and splines with Dr. Osita Onyejekwe\n\nThese courses are scoped to what I consider to be the statistical foundation of regression and regression-adjacent modeling, in contrast to the jump to machine learning where we focus more heavily on nonparametric methods, though there is some overlap. In particular, I like the broader progression in the order in which I took these courses and that spans across courses:\nProbability -&gt; Statistical Estimation -&gt; Hypothesis Testing -&gt; Regression -&gt; ANOVA -&gt; Generalized Linear Models -&gt; Generalized Additive Models\nThe piece that clicked for me and helped my broader understanding of statistical modeling is the move from linear regression to generalized linear models (GLM) by adding link functions and to generalized additive models (GAM) where the relationship between the independent and dependent variables can be non-linear and nonparametric. This step from linear regression to GLMs to GAMs was a big ah-ha moment for me.\nMy notes and projects from these courses will inform and guide the direction of this book, pulling out the broader dialogue across the courses above and that progression from regression to GLMs to GAMS in particular while also providing anchor points from which to branch off into other texts and take detours into areas that ask for more time and exploration.\nThere are many books and other sources that I have used to build my understanding or have cited more directly throughout the book. I am also planning to use this opportunity to start incorporating research papers as well, another step that will take some orientation and practice. The references chapter includes both cited references and non-cited further reading texts.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Introduce me plz",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "99_references.html",
    "href": "99_references.html",
    "title": "References",
    "section": "",
    "text": "Further Reading\nWhile working on this book, I will add more texts here than may end up in the final draft. The standard for a text being added here is that I spent at least a few minutes looking over a text to determine if there is material that is related to what I would like to cover in my book and that looks useful for helping me to understand or think about concepts differently.\nLearning Statistics with R (Navarro 2019)\nAn Introduction to Mathematical Statistics (Corcoran 2017)\nAn Introduction to Statistical Learning (James et al. 2023)\nInterpretable Machine Learning (Molnar 2025)\nElements of Statistical Learning (Hastie, Tibshirani, and Friedman 2017)\nIntroductory Statistics (Illowsky and Dean 2013)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "99_references.html#bibliography",
    "href": "99_references.html#bibliography",
    "title": "References",
    "section": "Bibliography",
    "text": "Bibliography\n\n\nCorcoran, J. N. 2017. An Introduction to Mathematical\nStatistics.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The\nElements of Statistical Learning: Data Mining, Inference, and\nPrediction. 2nd ed. https://hastie.su.domains/ElemStatLearn/.\n\n\nIllowsky, Barbara, and Susan Dean. 2013. Introductory\nStatistics. https://openstax.org/details/books/introductory-statistics/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2023. An Introduction to Statistical Learning: With Applications in\nr. 2nd ed. https://www.statlearning.com/.\n\n\nMolnar, Christoph. 2025. Interpretable Machine Learning: A Guide for\nMaking Black Box Models Explainable. 3rd ed. https://christophm.github.io/interpretable-ml-book.\n\n\nNavarro, Danielle. 2019. Learning Statistics with r: A Tutorial for\nPsychology Students and Other Beginners (version 0.6). https://learningstatisticswithr.com/.",
    "crumbs": [
      "References"
    ]
  }
]